---
title: "Varbench"
author: "Meltem GÃ¼rel"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_document:
    theme: lumen
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

**Varbench** is a suite of tools developed to compare somatic variant callers for targeted deep sequencing data, run the best performing one to call somatic variants, and report the allele frequencies of these variants using estimate intervals.

**Varbench** comprises four pipelines, namely **simulate**, **compare**, **estimate** and **validate**. This report briefly describes each pipeline and reports the results obtained by running them on targeted deep sequencing ctDNA data.

# _simulate_: Simulating somatic mutations

Given a sample .bam file and a reference genome `simulate` will induce somatic mutations to create a normal-tumour sample pair. The given .bam file is partitioned into halves where one is kept as the NORMAL.bam and the other is submitted to Bamsurgeon; a tool for adding mutations to .bam files. The mutation spots and the allele frequency is chosen based on a beta distribution which we believe best reflects ctDNA mutation distributions. _Figure 1_ shows the pipeline flow.


```{r, echo=FALSE, out.width="500px", fig.align="center", fig.cap="Figure 1: simulate DAG", dpi=36}
knitr::include_graphics("advdags/simulate.png")
```

All of the pipelines can be configured via their respective configuration files - `congif.<pipe>.yml`. You can find these files in the `config` directory.

After you edit ```config.simulate.yml``` to specify the

* path to the reference genome file (```REFERENCE```),
* path to the paired-end .fastq read files (```SAMPLE1``` and ```SAMPLE2```),
* minimum and maximum coverage depth to filter reads (```MINDEPTH``` and ```MAXDEPTH```, default is 10 and 10K),
* directory to store the pipeline outputs (```OUT_DIR```, will be created if it doesn't exist already),
* number of processes to use (```NTHREADS```)

run `simulate` with

```sh
$ snakemake --snakefile simulate --configfile config.simulate.yml
```

## Results

### Setup

* **input reads:** `SLX-10378.s_1.r_1.fq`, `SLX-10378.s_1.r_2.fq`
* **input genome:** hg19
* **command:** ```snakemake --snakefile simulate --configfile config.simulate.yml```

### Read alignment

**ALIGNED SAMPLE STATS**  
_bwa-mem paired-end read alignment_  
```
466165 + 0 in total (QC-passed reads + QC-failed reads)
0 + 0 secondary
0 + 0 supplementary
0 + 0 duplicates
466165 + 0 mapped (100.00% : N/A)
466165 + 0 paired in sequencing
233740 + 0 read1
232425 + 0 read2
463222 + 0 properly paired (99.37% : N/A)
464814 + 0 with itself and mate mapped
1351 + 0 singletons (0.29% : N/A)
1290 + 0 with mate mapped to a different chr
133 + 0 with mate mapped to a different chr (mapQ>=5)
```

### Alignment partitioning

**NORMAL SAMPLE STATS**  
_aligned read partitioned into two, 1/2 taken as the normal_  
```
233118 + 0 in total (QC-passed reads + QC-failed reads)
0 + 0 secondary
0 + 0 supplementary
0 + 0 duplicates
233118 + 0 mapped (100.00% : N/A)
233118 + 0 paired in sequencing
116872 + 0 read1
116246 + 0 read2
231726 + 0 properly paired (99.40% : N/A)
232478 + 0 with itself and mate mapped
640 + 0 singletons (0.27% : N/A)
610 + 0 with mate mapped to a different chr
58 + 0 with mate mapped to a different chr (mapQ>=5)
```

**TUMOR SAMPLE BEFORE MODIFICATION STATS**  
_remaining 1/2 taken as the tumor template_  
```
233047 + 0 in total (QC-passed reads + QC-failed reads)
0 + 0 secondary
0 + 0 supplementary
0 + 0 duplicates
233047 + 0 mapped (100.00% : N/A)
233047 + 0 paired in sequencing
116868 + 0 read1
116179 + 0 read2
231496 + 0 properly paired (99.33% : N/A)
232336 + 0 with itself and mate mapped
711 + 0 singletons (0.31% : N/A)
680 + 0 with mate mapped to a different chr
75 + 0 with mate mapped to a different chr (mapQ>=5)
```

### Inducing mutations
_hotspots every 100bp windows starting at a random origin_  
_allele frequencies chosen from a beta distribution with $\alpha$=2 and $\beta$=5_  
_range scaled and shifted to `[0.001-0.3]`_  
_RVAF: requested variant allele frequency_  
```{r echo=FALSE}
mutations <- read.table("run1/simulate/SLX-10378.s_1.r_1.originals.txt", header = TRUE)
mutations[,-7]
```

```{r, echo=FALSE, out.width="500px", fig.align="center", fig.cap="Figure 2: Requested allele frequency histogram", dpi=36}
hist(mutations$RVAF, xlab = 'allele frequency',
     main = 'allele frequency distribution')
```

**TUMOUR SAMPLE AFTER MODIFICATION STATS**  
_tumour sample generated by inducing synthetic mutations with Bamsurgeon_  
```
233047 + 0 in total (QC-passed reads + QC-failed reads)
0 + 0 secondary
0 + 0 supplementary
0 + 0 duplicates
164767 + 0 mapped (70.70% : N/A)
233047 + 0 paired in sequencing
116868 + 0 read1
116179 + 0 read2
146562 + 0 properly paired (62.89% : N/A)
159990 + 0 with itself and mate mapped
4777 + 0 singletons (2.05% : N/A)
674 + 0 with mate mapped to a different chr
70 + 0 with mate mapped to a different chr (mapQ>=5)
```

_AVAF: actual variant allele frequency induced by Bamsurgeon_  

```{r tidy=TRUE}
mutations <- read.table("run1/simulate/SLX-10378.s_1.r_1.mutations.txt", header = TRUE)
mutations
```

```{r, echo=FALSE, out.width="500px", fig.align="center", fig.cap="Figure 3: Actual allele frequency histogram", dpi=36}
hist(mutations$AVAF, xlab = 'allele frequency',
     main = 'allele frequency distribution')
```

### Output

```{r tidy=TRUE}
#reports
list.files("run1/simulate/", pattern = "*.txt", full.names = TRUE)
#normal and tumor samples
list.files("run1/simulate/", pattern = "*bam*", full.names = TRUE)
#RVAF histogram
list.files("run1/simulate/", pattern = "*.pdf", full.names = TRUE)
```

# _compare_: Pick the best variant caller

With `compare` you can pick the best somatic variant caller for your data by comparing their $R^2$ for called and actual allele frequencies. _Figure 4_ shows the pipeline flow.


```{r, echo=FALSE, out.width="500px", fig.align="center", fig.cap="Figure 4: compare DAG", dpi=36}
knitr::include_graphics("advdags/compare.png")
```

To run `compare` you will need to install VarDict and SomaticSniper. These are already included in the conda environment. If, instead, you manually installed the dependencies please make sure to install these variant callers before you run `compare`. More variant callers will soon be integrated into **Varbench**.

`config.compare.yml` needs to be edited before running `compare`. Here the `NORMAL` and `TUMOUR` samples are the .bam files created with the `simulate` pipeline, and the `MUTATIONS` parameter refers to the list of mutations generated again with the same pipeline.

You also need to submit the

* path to the reference genome file (`REFERENCE`),
* directory to store the pipeline outputs (`OUT_DIR`, will be created if it doesn't exist already),
* number of processes to split into (`NTHREADS`)

To run `compare` issue
```sh
snakemake --snakefile compare --configfile config.compare.yml
```
in your terminal.


### Setup

- **input samples:** `SLX-10378.s_1.r_1.normal.bam`, `SLX-10378.s_1.r_1.tumour.bam`
- **input genome:** hg19
- **hotspots:** `SLX-10378.s_1.r_1.mutations.txt`
- **command:** ```snakemake --snakefile compare --configfile config.compare.yml```

### Quality metrics

**Vardict**  
```
            precision   recall	F-score	  Rsq
summ.mean   0.00661	    0.524   0.0131	  0.715
summ.sd	    0.00068     0.0545	0.00134	  0.062
```

**SomaticSniper**  
```
            precision	recall	F-score	  Rsq
summ.mean	0.0341	    0.334   0.0618    0.234
summ.sd	    0.00221	    0.0084	0.00367	  0.0398
```

#### $R^2$ distributions

**Vardict**

```{r, echo=FALSE, out.width="500px", fig.align="center", fig.cap="Figure 5: r2 distributions with vardict", dpi=36}
knitr::include_graphics("run1/compare/analysis/r2_vardict-1.png")
```

**SomaticSniper**

```{r, echo=FALSE, out.width="500px", fig.align="center", fig.cap="Figure 6: r2 distributions with somaticsniper", dpi=36}
knitr::include_graphics("run1/compare/analysis/r2_somaticsniper-1.png")
```

#### Allele frequency distributions

**Vardict**

```{r, echo=FALSE, out.width="500px", fig.align="center", fig.cap="Figure 7: AF distributions with vardict", dpi=36}
knitr::include_graphics("run1/compare/analysis/afdist_vardict-1.png")
```

**SomaticSniper**

```{r, echo=FALSE, out.width="500px", fig.align="center", fig.cap="Figure 8: AF distributions with somaticsniper", dpi=36}
knitr::include_graphics("run1/compare/analysis/afdist_somaticsniper-1.png")
```

<!-- #### Precision distributions -->

<!-- **Vardict** -->

<!-- ```{r, echo=FALSE, out.width="500px", fig.align="center", fig.cap="Figure 9: Precision distributions with vardict"} -->
<!-- knitr::include_graphics("run1/compare/analysis/precision_vardict-1.png") -->
<!-- ``` -->

<!-- **SomaticSniper** -->

<!-- ```{r, echo=FALSE, out.width="500px", fig.align="center", fig.cap="Figure 10: Precision distributions with somaticsniper"} -->
<!-- knitr::include_graphics("run1/compare/analysis/precision_somaticsniper-1.png") -->
<!-- ``` -->

<!-- #### Recall distributions -->

<!-- **Vardict** -->

<!-- ```{r, echo=FALSE, out.width="500px", fig.align="center", fig.cap="Figure 11: Recall distributions with vardict"} -->
<!-- knitr::include_graphics("run1/compare/analysis/recall_vardict-1.png") -->
<!-- ``` -->

<!-- **SomaticSniper** -->

<!-- ```{r, echo=FALSE, out.width="500px", fig.align="center", fig.cap="Figure 12: Recall distributions with somaticsniper"} -->
<!-- knitr::include_graphics("run1/compare/analysis/recall_somaticsniper-1.png") -->
<!-- ``` -->

<!-- #### F-Score distributions -->

<!-- **Vardict** -->

<!-- ```{r, echo=FALSE, out.width="500px", fig.align="center", fig.cap="Figure 13: F-Score distributions with vardict"} -->
<!-- knitr::include_graphics("run1/compare/analysis/fscore_vardict-1.png") -->
<!-- ``` -->

<!-- **SomaticSniper** -->

<!-- ```{r, echo=FALSE, out.width="500px", fig.align="center", fig.cap="Figure 14: F-Score distributions with somaticsniper"} -->
<!-- knitr::include_graphics("run1/compare/analysis/fscore_somaticsniper-1.png") -->
<!-- ``` -->

### Output

```{r tidy=TRUE}
#reports
list.files("run1/compare/analysis", pattern = "*.txt", full.names = TRUE)
#plots
list.files("run1/compare/analysis", pattern = "*.pdf", full.names = TRUE)
```

# _estimate_: Calling somatic mutations with allele frequency confidence intervals

Instead of reporting point estimates of allelic frequencies, `estimate` returns a list of somatic variants - called with the chosen software - with their interval estimates of allele frequencies. This measure provides a degree of confidence for the called variant. _Figure 9_ shows the pipeline flow.


```{r, echo=FALSE, out.width="500px", fig.align="center", fig.cap="Figure 9: estimate DAG", dpi=36}
knitr::include_graphics("advdags/estimate.png")
```

`estimate` requires at least one of VarDict or SomaticSniper to be installed. And you must specify either 'vardict' or 'somaticsniper' as the preferred `CALLER` in the `config.estimate.yml` configuration file. Example setup files are provided in the root directory: `config.estimate_vardict.yml` and `config.estimate_somaticsniper.yml`. The `NORMAL` and `TUMOUR` samples are the .bam files created with the `simulate` pipeline.

Also specify the

* path to the reference genome file (`REFERENCE`),
* directory to store the pipeline outputs (`OUT_DIR`, will be created if it doesn't exist already),
* number of processes to split into (`NTHREADS`)

`estimate` can then be executed with:

```sh
snakemake --snakefile estimate --configfile config.estimate.yml
```

### Setup

* **input samples:** SLX-10378.s\_1.r\_1.normal.bam, SLX-10378.s\_1.r\_1.tumour.bam
* **input genome:** hg19
* **caller:** Vardict, SomaticSniper (others will be added)
* **command:** ```snakemake --snakefile estimate --configfile config.estimate_<caller>.yml```

### Bootstrap Summary

```{r tidy=TRUE}
mutations.vardict <- droplevels(subset(read.table("run1/estimate_vardict/analysis/results.txt", header = TRUE),
                                median.allele.freq > 0))
head(mutations.vardict)
```

```{r tidy=TRUE}
mutations.somaticsniper <- droplevels(subset(read.table("run1/estimate_somaticsniper/analysis/results.txt", header = TRUE),
                                median.allele.freq > 0))
head(mutations.somaticsniper)
```

### Output

```{r tidy=TRUE}
#reports
list.files("run1/estimate_vardict/analysis", pattern = "*.txt", full.names = TRUE)
list.files("run1/estimate_somaticsniper/analysis", pattern = "*.txt", full.names = TRUE)
#plots
list.files("run1/estimate_vardict/analysis", pattern = "*.pdf", full.names = TRUE)
list.files("run1/estimate_somaticsniper/analysis", pattern = "*.pdf", full.names = TRUE)
```

# _validate_: Pick mutations for validation

When you create .VCF files with either ```compare``` or ```estimate``` you can run

```sh
snakemake --snakefile validate --configfile config.validate.yml
```

to receive a list of mutations you can use to validate the chosen variant caller's accuracy. The returned list comprises `NMUTATIONS` number of mutations that were picked uniformly among all the called mutations after ordering them by their coefficient of variation.  _Figure 10_ shows the pipeline flow.


```{r, echo=FALSE, out.width="150px", fig.align="center", fig.cap="Figure 10: validate DAG", dpi=36}
knitr::include_graphics("advdags/validate.png")
```

The ```VCF_DIR``` parameter in the ```config.validate.yml``` should point to the .VCF files and ```NMUTATIONS``` refers to the number of mutations you wish to validate.

Other required fields are the

* directory to store the pipeline outputs (```OUT_DIR```, will be created if it doesn't exist already),
* the variant caller used to generate the .VCF files (```CALLER```)
* number of processes to split into (```NTHREADS```)

### Setup

* **input VCFs:** Bootstrap generated VCF files (generated with `compare` or `estimate`)
* **number of mutations to validate:** 20
* **caller:** Vardict, SomaticSniper (others will be added)
* **command:** ```snakemake --snakefile validate --configfile config.validate_<caller>.yml```

### Output - List of mutations to validate (n=20)

**Vardict**

```{r tidy=TRUE}
mutations.vardict <- read.table("run1/validate_vardict/analysis/results.txt", header = TRUE)
mutations.vardict
```

**SomaticSniper**

```{r tidy=TRUE}
mutations.somaticsniper <- read.table("run1/validate_somaticsniper/analysis/results.txt", header = TRUE)
mutations.somaticsniper
```

### Output

```{r tidy=TRUE}
#reports
list.files("run1/validate_vardict/analysis", pattern = "*.txt", full.names = TRUE)
list.files("run1/validate_somaticsniper/analysis", pattern = "*.txt", full.names = TRUE)
#allele frequency density plots
list.files("run1/validate_vardict/analysis", pattern = "*.pdf", full.names = TRUE)
list.files("run1/validate_somaticsniper/analysis", pattern = "*.pdf", full.names = TRUE)
```

# Full Varbench execution:

```
snakemake --snakefile simulate
          --configfile config.simulate.yml;
snakemake --snakefile compare
          --configfile config.compare.yml;
snakemake --snakefile estimate
          --configfile config.estimate_vardict.yml;
snakemake --snakefile estimate
          --configfile config.estimate_somaticsniper.yml;
snakemake --snakefile validate
          --configfile config.validate_vardict.yml;
snakemake --snakefile validate
          --configfile config.validate_somaticsniper.yml;
```

# Runtimes

```{r, echo=FALSE, out.width="600px", fig.align="center", fig.cap="Figure 11: runtime for simulate", dpi=36}
knitr::include_graphics("advdags/simulate-RT.png")
```

----

```{r, echo=FALSE, out.width="600px", fig.align="center", fig.cap="Figure 12: runtime for compare", dpi=36}
knitr::include_graphics("advdags/compare-RT.png")
```

----

```{r, echo=FALSE, out.width="600px", fig.align="center", fig.cap="Figure 13: runtime for estimate", dpi=36}
knitr::include_graphics("advdags/estimate-RT.png")
```

----

```{r, echo=FALSE, out.width="250px", fig.align="center", fig.cap="Figure 14: runtime for validate", dpi=36}
knitr::include_graphics("advdags/validate-RT.png")
```